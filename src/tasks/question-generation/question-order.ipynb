{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ubuntu/anaconda3/envs/omdena_hyd_chatbot/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Position</th>\n",
       "      <th>Interview Phase</th>\n",
       "      <th>Sequence of Interview Phase</th>\n",
       "      <th>Number of questions for this interview phase</th>\n",
       "      <th>Number of LLM Generation questions</th>\n",
       "      <th>Preset Question 1 (Backup if no question could be generated)</th>\n",
       "      <th>Preset Question 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduction Q1</td>\n",
       "      <td>Introduction Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>Behavioral</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Behavioral Q1</td>\n",
       "      <td>Behavioral Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>Communication</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Communication Q1</td>\n",
       "      <td>Communication Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>Technical</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Technical Q1</td>\n",
       "      <td>Technical Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>Conclusion</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Conclusion Q1</td>\n",
       "      <td>Conclusion Q2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Job Position  Interview Phase   Sequence of Interview Phase  \\\n",
       "0        Nurse     Introduction                             1   \n",
       "1        Nurse       Behavioral                             2   \n",
       "2        Nurse    Communication                             3   \n",
       "3        Nurse        Technical                             4   \n",
       "4        Nurse       Conclusion                             5   \n",
       "\n",
       "    Number of questions for this interview phase  \\\n",
       "0                                              2   \n",
       "1                                              2   \n",
       "2                                              2   \n",
       "3                                              2   \n",
       "4                                              2   \n",
       "\n",
       "    Number of LLM Generation questions  \\\n",
       "0                                    1   \n",
       "1                                    1   \n",
       "2                                    1   \n",
       "3                                    1   \n",
       "4                                    1   \n",
       "\n",
       "   Preset Question 1 (Backup if no question could be generated)  \\\n",
       "0                                    Introduction Q1              \n",
       "1                                      Behavioral Q1              \n",
       "2                                   Communication Q1              \n",
       "3                                       Technical Q1              \n",
       "4                                      Conclusion Q1              \n",
       "\n",
       "   Preset Question 2  \n",
       "0    Introduction Q2  \n",
       "1      Behavioral Q2  \n",
       "2   Communication Q2  \n",
       "3       Technical Q2  \n",
       "4      Conclusion Q2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nurse_df = pd.read_csv('./question-order.csv')\n",
    "nurse_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Job Position', 'Interview Phase', 'Sequence of Interview Phase',\n",
       "       'Number of questions for this interview phase',\n",
       "       'Number of LLM Generation questions',\n",
       "       'Preset Question 1 (Backup if no question could be generated)',\n",
       "       'Preset Question 2'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nurse_df.columns = nurse_df.columns.str.strip()\n",
    "nurse_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Position</th>\n",
       "      <th>Interview Phase</th>\n",
       "      <th>Sequence of Interview Phase</th>\n",
       "      <th>Number of questions for this interview phase</th>\n",
       "      <th>Number of LLM Generation questions</th>\n",
       "      <th>Preset Question 1 (Backup if no question could be generated)</th>\n",
       "      <th>Preset Question 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Introduction Q1</td>\n",
       "      <td>Introduction Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>Behavioral</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Behavioral Q1</td>\n",
       "      <td>Behavioral Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>Communication</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Communication Q1</td>\n",
       "      <td>Communication Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>Technical</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Technical Q1</td>\n",
       "      <td>Technical Q2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nurse</td>\n",
       "      <td>Conclusion</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Conclusion Q1</td>\n",
       "      <td>Conclusion Q2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Job Position Interview Phase  Sequence of Interview Phase  \\\n",
       "0        Nurse    Introduction                            1   \n",
       "1        Nurse      Behavioral                            2   \n",
       "2        Nurse   Communication                            3   \n",
       "3        Nurse       Technical                            4   \n",
       "4        Nurse      Conclusion                            5   \n",
       "\n",
       "   Number of questions for this interview phase  \\\n",
       "0                                             2   \n",
       "1                                             2   \n",
       "2                                             2   \n",
       "3                                             2   \n",
       "4                                             2   \n",
       "\n",
       "   Number of LLM Generation questions  \\\n",
       "0                                   1   \n",
       "1                                   1   \n",
       "2                                   1   \n",
       "3                                   1   \n",
       "4                                   1   \n",
       "\n",
       "  Preset Question 1 (Backup if no question could be generated)  \\\n",
       "0                                    Introduction Q1             \n",
       "1                                      Behavioral Q1             \n",
       "2                                   Communication Q1             \n",
       "3                                       Technical Q1             \n",
       "4                                      Conclusion Q1             \n",
       "\n",
       "   Preset Question 2  \n",
       "0    Introduction Q2  \n",
       "1      Behavioral Q2  \n",
       "2   Communication Q2  \n",
       "3       Technical Q2  \n",
       "4      Conclusion Q2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nurse_df.sort_values(by=['Sequence of Interview Phase'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "chroma_client = chromadb.PersistentClient(path='/home/ubuntu/Desktop/Anand/Research/omdena-hyderabad-Chatbot-for-interview/src/data/chromadb')\n",
    "huggingface_ef = embedding_functions.HuggingFaceEmbeddingFunction(\n",
    "    api_key='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',\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    ")\n",
    "\n",
    "question_collection = chroma_client.get_collection(\n",
    "    name='question_collection', embedding_function=huggingface_ef\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_profile = \"\"\"\n",
    "Dedicated and compassionate Registered Nurse with a diverse background in healthcare. Holds a [Degree or Certification] in Nursing from [Institution]. Proven expertise in providing patient-centered care, managing medical records, and collaborating with interdisciplinary teams. Skilled in administering medications, monitoring vital signs, and implementing nursing care plans. Demonstrates strong communication and interpersonal skills, fostering positive relationships with patients, families, and healthcare professionals. Upholds a commitment to continuous learning and professional development. Adept at maintaining a calm and focused demeanor in high-pressure situations. Excited about contributing clinical skills and compassionate care to a dynamic healthcare environment. [Optional: Specify any specializations, such as critical care, pediatrics, or other relevant areas of expertise.]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "\n",
      "\n",
      "=============================\n",
      "{'ids': [['q_id1021']], 'distances': [[0.3737702965736389]], 'metadatas': [[{'interview_phase': 'Introduction', 'position': 'Nurse'}]], 'embeddings': None, 'documents': [['what do you think are the most important qualities of a successful nurse']], 'uris': None, 'data': None}\n",
      "1\n",
      "\n",
      "\n",
      "=============================\n",
      "{'ids': [['q_id974']], 'distances': [[0.48121243715286255]], 'metadatas': [[{'interview_phase': 'Behavioral', 'position': 'Nurse'}]], 'embeddings': None, 'documents': [['why did you want to be a nurse']], 'uris': None, 'data': None}\n",
      "1\n",
      "\n",
      "\n",
      "=============================\n",
      "{'ids': [['q_id1959']], 'distances': [[0.4316323399543762]], 'metadatas': [[{'interview_phase': 'Communication', 'position': 'Nurse'}]], 'embeddings': None, 'documents': [[\"can you explain the role of a nursing assistant in a patient's plan of care\"]], 'uris': None, 'data': None}\n",
      "1\n",
      "\n",
      "\n",
      "=============================\n",
      "{'ids': [['q_id1929']], 'distances': [[0.42420780658721924]], 'metadatas': [[{'interview_phase': 'Technical', 'position': 'Nurse'}]], 'embeddings': None, 'documents': [['how do you use organizational skills in your daily responsibilities as a nurse']], 'uris': None, 'data': None}\n",
      "1\n",
      "\n",
      "\n",
      "=============================\n",
      "{'ids': [['q_id800']], 'distances': [[0.35868310928344727]], 'metadatas': [[{'interview_phase': 'Conclusion', 'position': 'Nurse'}]], 'embeddings': None, 'documents': [['tell me what you feel your greatest skill as a nurse is']], 'uris': None, 'data': None}\n"
     ]
    }
   ],
   "source": [
    "question_from_semantic_search = []\n",
    "\n",
    "for _index, nurse in nurse_df.iterrows():\n",
    "    print((int(nurse['Number of questions for this interview phase']) - int(nurse['Number of LLM Generation questions'])))\n",
    "    result = question_collection.query(\n",
    "        query_texts=[candidate_profile],\n",
    "        where={\n",
    "            \"$and\": [\n",
    "                {\"position\": {\"$eq\": nurse['Job Position'].strip()}},\n",
    "                {\"interview_phase\": {\"$eq\": nurse[\"Interview Phase\"].strip()}},\n",
    "            ]\n",
    "        },\n",
    "        n_results=(int(nurse['Number of questions for this interview phase']) - int(nurse['Number of LLM Generation questions'])),\n",
    "    )\n",
    "    print('\\n\\n=============================')\n",
    "    print(result)\n",
    "    question_from_semantic_search.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'ids': [['q_id1021']],\n",
       "  'distances': [[0.3737702965736389]],\n",
       "  'metadatas': [[{'interview_phase': 'Introduction', 'position': 'Nurse'}]],\n",
       "  'embeddings': None,\n",
       "  'documents': [['what do you think are the most important qualities of a successful nurse']],\n",
       "  'uris': None,\n",
       "  'data': None},\n",
       " {'ids': [['q_id974']],\n",
       "  'distances': [[0.48121243715286255]],\n",
       "  'metadatas': [[{'interview_phase': 'Behavioral', 'position': 'Nurse'}]],\n",
       "  'embeddings': None,\n",
       "  'documents': [['why did you want to be a nurse']],\n",
       "  'uris': None,\n",
       "  'data': None},\n",
       " {'ids': [['q_id1959']],\n",
       "  'distances': [[0.4316323399543762]],\n",
       "  'metadatas': [[{'interview_phase': 'Communication', 'position': 'Nurse'}]],\n",
       "  'embeddings': None,\n",
       "  'documents': [[\"can you explain the role of a nursing assistant in a patient's plan of care\"]],\n",
       "  'uris': None,\n",
       "  'data': None},\n",
       " {'ids': [['q_id1929']],\n",
       "  'distances': [[0.42420780658721924]],\n",
       "  'metadatas': [[{'interview_phase': 'Technical', 'position': 'Nurse'}]],\n",
       "  'embeddings': None,\n",
       "  'documents': [['how do you use organizational skills in your daily responsibilities as a nurse']],\n",
       "  'uris': None,\n",
       "  'data': None},\n",
       " {'ids': [['q_id800']],\n",
       "  'distances': [[0.35868310928344727]],\n",
       "  'metadatas': [[{'interview_phase': 'Conclusion', 'position': 'Nurse'}]],\n",
       "  'embeddings': None,\n",
       "  'documents': [['tell me what you feel your greatest skill as a nurse is']],\n",
       "  'uris': None,\n",
       "  'data': None}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_from_semantic_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/omdena_hyd_chatbot/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================\n",
      "Introduction\n",
      "\n",
      "1. As a Registered Nurse, what inspired you to pursue a career in healthcare, and how do you envision contributing to a healthcare team?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/omdena_hyd_chatbot/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================\n",
      "Behavioral\n",
      "\n",
      "1. As a Registered Nurse, how have you handled difficult patients or their families in the past, and how do you typically approach challenging situations?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/omdena_hyd_chatbot/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================\n",
      "Communication\n",
      "\n",
      "1. As a Registered Nurse, what strategies do you use to effectively communicate with patients and their families?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/omdena_hyd_chatbot/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================\n",
      "Technical\n",
      "\n",
      "1. As a Registered Nurse, what strategies do you use to ensure patient safety during medication administration?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/omdena_hyd_chatbot/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'InferenceApi' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=============================\n",
      "Conclusion\n",
      "\n",
      "1. As a Registered Nurse with your background and experience, what do you consider your greatest professional accomplishment and challenge in your career so far?\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "for _index, nurse in nurse_df.iterrows():\n",
    "    position = nurse['Job Position'].strip()\n",
    "    interview_phase = nurse['Interview Phase'].strip()\n",
    "    num_ques_to_gen = int(nurse['Number of LLM Generation questions'])\n",
    "    intro_template = \"\"\"Assume you are an expert interviewer, interviewing a candidate. You have the following information:\n",
    "    Position applying for : {position}\n",
    "    Candidate profile summary : {candidate_profile}.\n",
    "    Using the above information, generate {num_ques_to_gen} {interview_phase} question/questions which can help start off the interview. Please provide questions that are highly relevant for the job position only. Don't ask irrelevant questions.\"\"\"\n",
    "\n",
    "    # intro_ques_llm = llm_inference(\n",
    "    #     model_type=\"huggingface\",\n",
    "    #     input_variables_list=[position, candidate_profile, num_ques_to_gen],\n",
    "    #     prompt_template=intro_template,\n",
    "    #     hf_repo_id=\"tiiuae/falcon-7b-instruct\",\n",
    "    #     temperature=0.1,\n",
    "    #     max_length=64,\n",
    "    # )\n",
    "    llm = HuggingFaceHub(\n",
    "        repo_id=\"tiiuae/falcon-7b-instruct\",\n",
    "        model_kwargs={\"temperature\": 0.1, \"max_length\": 64} )\n",
    "    llm_chain = LLMChain(prompt=PromptTemplate(\n",
    "          template=intro_template, input_variables=[position, candidate_profile, num_ques_to_gen, interview_phase]\n",
    "    ), llm=llm)\n",
    "\n",
    "    result = llm_chain.predict(\n",
    "        position=position,\n",
    "        candidate_profile=candidate_profile,\n",
    "        num_ques_to_gen=num_ques_to_gen,\n",
    "        interview_phase=interview_phase\n",
    "    )\n",
    "    print('\\n\\n=============================')\n",
    "    print(interview_phase)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omdena_hyd_chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
